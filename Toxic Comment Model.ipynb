{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this competition , we are asked to predict the toxicity rating of the comments taking into consideration the bias.Lets try it out."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport time\nimport warnings\nfrom tqdm import tqdm\nimport gc\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir(\"../input\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ntrain=pd.read_csv(\"../input/toxic-comment-clean/train_cleaned.csv\")\ntest=pd.read_csv(\"../input/toxic-comment-clean/test_cleaned.csv\")\nsubmission=pd.read_csv(\"../input/jigsaw-unintended-bias-in-toxicity-classification/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We use the fasttext embeddings here .All codes are borrowed/inspired from theo veils kernel -https://www.kaggle.com/theoviel/improve-your-score-with-some-text-preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"EMB_PATH='../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_coefs(word,*arr): \n    return word, np.asarray(arr, dtype='float32')\n\ndef load_embed(embed_dir=EMB_PATH):\n    embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in tqdm(open(embed_dir)))\n    gc.collect()\n    return embedding_index\n\n# def build_vocab(texts):\n#     sentences = texts.apply(lambda x: x.split()).values\n#     vocab = {}\n#     for sentence in sentences:\n#         for word in sentence:\n#             try:\n#                 vocab[word] += 1\n#             except KeyError:\n#                 vocab[word] = 1\n#     return vocab\n\n# def check_coverage(vocab, embeddings_index):\n#     known_words = {}\n#     unknown_words = {}\n#     nb_known_words = 0\n#     nb_unknown_words = 0\n#     for word in vocab.keys():\n#         try:\n#             known_words[word] = embeddings_index[word]\n#             nb_known_words += vocab[word]\n#         except:\n#             unknown_words[word] = vocab[word]\n#             nb_unknown_words += vocab[word]\n#             pass\n\n#     print('Found embeddings for {:.2%} of vocab'.format(len(known_words) / len(vocab)))\n#     print('Found embeddings for  {:.2%} of all text'.format(nb_known_words / (nb_known_words + nb_unknown_words)))\n#     unknown_words = sorted(unknown_words.items(), key=operator.itemgetter(1))[::-1]\n\n#     return unknown_words\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Loading the embedding,\n\nembed =load_embed()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n        \n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=reduce_mem_usage(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# vocab=build_vocab(train['comment_text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# oov_fasttext=check_coverage(vocab,embed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets get to modelling  . Inspired from this kernel - https://www.kaggle.com/thousandvoices/simple-lstm"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Input, Dense, Embedding, SpatialDropout1D, Dropout, add, concatenate\nfrom keras.layers import CuDNNLSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D\nfrom keras.preprocessing import text, sequence\nfrom keras.callbacks import LearningRateScheduler\nfrom sklearn.model_selection import train_test_split,StratifiedKFold\nfrom sklearn import metrics\nfrom keras.callbacks import ModelCheckpoint, TensorBoard, Callback, EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# del(vocab,vocab_test,oov_fasttext,oof_fasttext_test)\n# gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_matrix(word_index,embedding_index):\n    embedding_matrix = np.zeros((len(word_index) + 1, 300))\n    for word, i in word_index.items():\n        try:\n            embedding_matrix[i] = embedding_index[word]\n        except KeyError:\n            pass\n    return embedding_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"identity_columns = [\n    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\nfor col in identity_columns + ['target']:\n    print(f'\\n Converting {col} to boolean')\n    train[col]=np.where(train[col]>=0.5,True,False)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#x_train=train['comment_treated']\ny_train=np.where(train['target']>=0.5,True,False)*1\n#y_aux_train = train[['target', 'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish','muslim', 'black', 'white', 'psychiatric_or_mental_illness']]\n#x_test=test['comment_treated']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(f'Shape of x_train {x_train.shape} \\n Shape of y_train {y_train.shape} \\n Shape of x_test {x_test.shape}'\n# )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ntokenizer = text.Tokenizer(num_words=90000)\ntokenizer.fit_on_texts(list(train['comment_treated'])+list(test['comment_treated']))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_LEN=220\nLSTM_UNITS=128\nNUM_MODELS = 1\nBATCH_SIZE = 512\nDENSE_HIDDEN_UNITS = 2 * LSTM_UNITS\nEPOCHS = 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_matrix=build_matrix(tokenizer.word_index,embed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Defining the metrics:\n### https://www.kaggle.com/dborkan/benchmark-kernel/\nSUBGROUP_AUC = 'subgroup_auc'\nBPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\nBNSP_AUC = 'bnsp_auc'  # stands for background negative, subgroup positive\n\ndef compute_auc(y_true, y_pred):\n    try:\n        return metrics.roc_auc_score(y_true, y_pred)\n    except ValueError:\n        return np.nan\n\ndef compute_subgroup_auc(df, subgroup, label, model_name):\n    subgroup_examples = df[df[subgroup]]\n    return compute_auc(subgroup_examples[label], subgroup_examples[model_name])\n\ndef compute_bpsn_auc(df, subgroup, label, model_name):\n    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n    subgroup_negative_examples = df[df[subgroup] & ~df[label]]\n    non_subgroup_positive_examples = df[~df[subgroup] & df[label]]\n    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n    return compute_auc(examples[label], examples[model_name])\n\ndef compute_bnsp_auc(df, subgroup, label, model_name):\n    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n    subgroup_positive_examples = df[df[subgroup] & df[label]]\n    non_subgroup_negative_examples = df[~df[subgroup] & ~df[label]]\n    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n    return compute_auc(examples[label], examples[model_name])\n\ndef compute_bias_metrics_for_model(dataset,\n                                   subgroups,\n                                   model,\n                                   label_col,\n                                   include_asegs=False):\n    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n    records = []\n    for subgroup in subgroups:\n        record = {\n            'subgroup': subgroup,\n            'subgroup_size': len(dataset[dataset[subgroup]])\n        }\n        record[SUBGROUP_AUC] = compute_subgroup_auc(dataset, subgroup, label_col, model)\n        record[BPSN_AUC] = compute_bpsn_auc(dataset, subgroup, label_col, model)\n        record[BNSP_AUC] = compute_bnsp_auc(dataset, subgroup, label_col, model)\n        records.append(record)\n    return pd.DataFrame(records).sort_values('subgroup_auc', ascending=True)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_overall_auc(df, model_name):\n    true_labels = df['target']\n    predicted_labels = df[oof_name]\n    return metrics.roc_auc_score(true_labels, predicted_labels)\n\ndef power_mean(series, p):\n    total = sum(np.power(series, p))\n    return np.power(total / len(series), 1 / p)\n\ndef get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n    bias_score = np.average([\n        power_mean(bias_df[SUBGROUP_AUC], POWER),\n        power_mean(bias_df[BPSN_AUC], POWER),\n        power_mean(bias_df[BNSP_AUC], POWER)\n    ])\n    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(x_train,y_train,x_valid,y_valid,embedding_matrix,patience=3):\n    \n    early_stop = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=patience)\n    words = Input(shape=(MAX_LEN,))\n    x = Embedding(*embedding_matrix.shape, weights=[embedding_matrix], trainable=False)(words)\n    x = SpatialDropout1D(0.3)(x)\n    x = Bidirectional(CuDNNLSTM(LSTM_UNITS, return_sequences=True))(x)\n\n    hidden = GlobalMaxPooling1D()(x)\n    hidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation='tanh')(hidden)])\n    result = Dense(1, activation='sigmoid')(hidden)\n    model = Model(inputs=words, outputs=result)\n    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\"])\n    model.fit(x_train,y_train,batch_size=128,epochs=3, validation_data=(x_valid, y_valid), \n                        verbose=2, callbacks=[early_stop])\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# n_fold = 2\n# folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=11)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_valid,y_train,y_valid=train_test_split(train,y_train,test_size=0.2,random_state=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_tokenized = tokenizer.texts_to_sequences(test['comment_text'])\nX_test = sequence.pad_sequences(test_tokenized, maxlen = MAX_LEN)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction=np.zeros((len(X_test),1))\nprint(\"\\n Starting tokenizing\")\ntrain_tokenised=tokenizer.texts_to_sequences(x_train['comment_treated'])\nvalid_tokenised=tokenizer.texts_to_sequences(x_valid['comment_treated'])\nprint(\"\\n Starting padding\")\nX_train=sequence.pad_sequences(train_tokenised,maxlen=MAX_LEN)\nX_valid=sequence.pad_sequences(valid_tokenised,maxlen=MAX_LEN)\nprint(\"\\n Building model\")\nmodel = build_model(X_train, y_train, X_valid, y_valid,embedding_matrix,patience=3)\ngc.collect()\nprint(model.summary())\nprint(\"\\n Validation prediction\")\npred_valid = model.predict([X_valid])\n#valid_df=X_valid.copy()\n#valid_df['predicted_target']=pred_valid\n#bias_metrics_df = compute_bias_metrics_for_model(pred_valid, identity_columns, oof_name, 'target')\n#scores.append(get_final_metric(bias_metrics_df, calculate_overall_auc(pred_valid, oof_name)))\nprint(\"\\n Test set prediction\")\nprediction += model.predict(X_test, batch_size = 1024, verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # valid_checkpoint_predictions = []\n# # checkpoint_predictions=[]\n# # valid_weights = []\n# # weights=[]\n# # for model_idx in range(NUM_MODELS):\n# #     model = build_model(embedding_matrix, y_aux_train_df.shape[-1])\n# #     for global_epoch in range(EPOCHS):\n# #         model.fit(\n# #             x_train_df,\n# #             [y_train_df,y_aux_train_df],\n# #             batch_size=BATCH_SIZE,\n# #             epochs=1,\n# #             verbose=2,\n# #             callbacks=[\n# #                 LearningRateScheduler(lambda epoch: 1e-3 * (0.6 ** global_epoch))\n# #             ]\n# #         )\n# #         valid_checkpoint_predictions.append(model.predict(x_valid_df, batch_size=2048)[0].flatten())\n# #         valid_weights.append(2 ** global_epoch)\n# # checkpoint_predictions.append(model.predict(x_test,batch=2048)[0].flatten())\n\n\n# # predictions = np.average(checkpoint_predictions, axis=0)\n\n# def train_model(X, X_test, y):\n    \n#     oof = np.zeros((len(X), 1))\n#     prediction = np.zeros((len(X_test), 1))\n#     scores = []\n#     print(\"\\n Started tokenizing for test set\")\n#     test_tokenized = tokenizer.texts_to_sequences(test['comment_text'])\n#     X_test = sequence.pad_sequences(test_tokenized, maxlen = MAX_LEN)\n#     print(\"\\n Completed tokenizing and padding.Starting the train-valid epochs.\")\n#     for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n#         print('Fold', fold_n, 'started at', time.ctime())\n#         X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n#         y_train, y_valid = y[train_index], y[valid_index]\n#         valid_df = X_valid.copy()    \n#         print(f'\\n Tokenizing for fold {fold_n}')\n#         train_tokenised=tokenizer.texts_to_sequences(X_train['comment_treated'])\n#         valid_tokenised=tokenizer.texts_to_sequences(X_valid['comment_treated'])\n#         print(f'\\n Tokenising completed.Starting padding for fold {fold_n}')\n#         X_train=sequence.pad_sequences(train_tokenised,maxlen=MAX_LEN)\n#         X_valid=sequence.pad_sequences(valid_tokenised,maxlen=MAX_LEN)\n#         print(f'\\n Padding completed .Started model building for fold {fold_n}')\n#         model = build_model(X_train, y_train, X_valid, y_valid,embedding_matrix,patience=3)\n#         print(f'\\n Model building completed for fold {fold_n}')\n#         pred_valid = model.predict(X_valid)\n#         oof[valid_index] = pred_valid\n#         valid_df[oof_name] = pred_valid\n#         print(\"Started calculating the bias metric and final metric\")\n#         bias_metrics_df = compute_bias_metrics_for_model(valid_df, identity_columns, oof_name, 'target')\n#         scores.append(get_final_metric(bias_metrics_df, calculate_overall_auc(valid_df, oof_name)))\n#         print(\"Completed finding the bias metric.Started prediction for test set\")\n#         prediction += model.predict(X_test, batch_size = 1024, verbose = 1)\n    \n#     prediction /= n_fold\n    \n#     # print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n#     return oof, prediction, scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# oof_name = 'predicted_target'\n# oof, prediction, scores = train_model(X=train, X_test=test, y=y_train)\n# print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['prediction']=prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}